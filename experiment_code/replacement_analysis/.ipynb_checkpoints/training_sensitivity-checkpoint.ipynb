{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df7e4d7-d4d9-4c86-9c53-549b01dee1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils      import *\n",
    "from model_utils     import get_network\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms as T\n",
    "from matplotlib import cm\n",
    "import torchvision\n",
    "from random import shuffle, choice, seed\n",
    "import seaborn as sns\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76d3633-0e5c-4074-b36d-af4e31ae093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "channel, im_size, train_n_classes, test_n_classes, dst_train, dst_test = get_dataset(\n",
    "        \"CIFAR10\",\n",
    "        \"../../data\",\n",
    "        zca=False\n",
    "    )\n",
    "assert train_n_classes == test_n_classes\n",
    "test_loader = torch.utils.data.DataLoader(dst_test, batch_size=256, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa5dc2c-d716-44e2-afaa-45df92088f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 46.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 32, 32])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "test_img = []\n",
    "test_label = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(test_loader):\n",
    "        test_img.append(x)\n",
    "        test_label.append(y)\n",
    "test_img = torch.vstack(test_img).to(device)\n",
    "test_label = torch.hstack(test_label).to(device)\n",
    "print(test_img.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361c67d-9792-4089-a2e6-e9b88c41b393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                    | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                                                                                    | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████████████████████████████                                                                                                                                                                                             | 1/4 [00:01<00:05,  1.92s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2/4 [00:03<00:03,  1.73s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 3/4 [00:05<00:01,  1.68s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.69s/it]\u001b[A\n",
      " 20%|██████████████████████████████████████████████████▍                                                                                                                                                                                                         | 1/5 [00:06<00:27,  6.78s/it]\n",
      "  0%|                                                                                                                                                                                                                                                                    | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████████████████████████████                                                                                                                                                                                             | 1/4 [00:01<00:05,  1.80s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2/4 [00:03<00:03,  1.74s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 3/4 [00:05<00:01,  1.74s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.75s/it]\u001b[A\n",
      " 40%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                       | 2/5 [00:21<00:34, 11.55s/it]\n",
      "  0%|                                                                                                                                                                                                                                                                    | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████████████████████████████                                                                                                                                                                                             | 1/4 [00:02<00:07,  2.65s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2/4 [00:05<00:05,  2.58s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 3/4 [00:07<00:02,  2.55s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.55s/it]\u001b[A\n",
      " 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 3/5 [00:39<00:29, 14.56s/it]\n",
      "  0%|                                                                                                                                                                                                                                                                    | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████████████████████████████                                                                                                                                                                                             | 1/4 [00:06<00:18,  6.25s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2/4 [00:12<00:12,  6.19s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 3/4 [00:18<00:06,  6.19s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.18s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 4/5 [01:12<00:21, 21.69s/it]\n",
      "  0%|                                                                                                                                                                                                                                                                    | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|███████████████████████████████████████████████████████████████                                                                                                                                                                                             | 1/4 [00:24<01:13, 24.42s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2/4 [00:48<00:48, 24.42s/it]\u001b[A\n",
      " 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                               | 3/4 [01:13<00:24, 24.41s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "# generate mixing accuracy for distilled data\n",
    "ipc_acc = []\n",
    "for ipc in tqdm([0, 2, 10, 50, 250]):\n",
    "    if ipc != 0:\n",
    "        label_indices = [[] for _ in range(train_n_classes)]\n",
    "        for i, (x,y) in enumerate(dst_train):\n",
    "            label_indices[y].append(i)\n",
    "        seed(1) # fix seed\n",
    "        for list in label_indices:\n",
    "            shuffle(list)\n",
    "        indices = []\n",
    "        for list in label_indices:\n",
    "            indices += list[:ipc]\n",
    "        dst_train_subset = torch.utils.data.Subset(dst_train, indices)\n",
    "        train_loader_subset = torch.utils.data.DataLoader(dst_train_subset, batch_size=256, shuffle=False, num_workers=8)\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        for x,y in train_loader_subset:\n",
    "            train_data.append(x.detach())\n",
    "            train_label.append(y.detach())\n",
    "        train_data = torch.vstack(train_data).to(device)\n",
    "        train_label = torch.hstack(train_label).to(device)\n",
    "    \n",
    "    distilled_acc = []\n",
    "    for i in tqdm(range(4)):\n",
    "        data = torch.load(f\"../../DD_data/{i}.pt\")\n",
    "        synthetic_data = data[\"data\"]\n",
    "        synthetic_label = data[\"label\"]\n",
    "        if ipc == 0:\n",
    "            new_data = synthetic_data.to(device)\n",
    "            new_label = synthetic_label.to(device)\n",
    "        else: # combine distilled and real data\n",
    "            new_data = torch.vstack([synthetic_data, train_data]).to(device)\n",
    "            new_label = torch.hstack([synthetic_label, train_label]).to(device)\n",
    "        torch.manual_seed(1) # fix seed to remove impact of random initialization\n",
    "        np.random.seed(1)\n",
    "        distilled_model = get_network(\"ConvNet\", channel, train_n_classes, im_size).to(device)\n",
    "        optim = torch.optim.SGD(distilled_model.parameters(), lr=0.01, momentum=0.9)\n",
    "        distilled_model.train()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        for e in range(300):\n",
    "            pred = distilled_model(new_data)\n",
    "            assert len(pred) == 1\n",
    "            loss = criterion(pred[-1], new_label)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        distilled_model.eval()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        test_predictions = []\n",
    "        correctness = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                pred = distilled_model(x)\n",
    "                assert len(pred) == 1\n",
    "                pred = torch.argmax(pred[-1], dim=1)\n",
    "                test_predictions += pred.tolist()\n",
    "                correctness += (pred == y).tolist()\n",
    "                correct += torch.sum(pred == y).item()\n",
    "                total += x.shape[0]\n",
    "        test_accuracy = correct/total\n",
    "        distilled_acc.append(test_accuracy)\n",
    "    ipc_acc.append(distilled_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeee048-57e7-44d3-a181-9a7790b10782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate accuracies for real data\n",
    "seed(9999)\n",
    "rand_acc = []\n",
    "label_indices = [[] for _ in range(train_n_classes)]\n",
    "for i, (x,y) in enumerate(dst_train):\n",
    "    label_indices[y].append(i)\n",
    "for list in label_indices:\n",
    "    shuffle(list)\n",
    "indices = []\n",
    "for list in label_indices:\n",
    "    indices += list[:10]\n",
    "dst_train_subset = torch.utils.data.Subset(dst_train, indices)\n",
    "train_loader_subset = torch.utils.data.DataLoader(dst_train_subset, batch_size=256, shuffle=False, num_workers=8)\n",
    "train_data = []\n",
    "train_label = []\n",
    "for x,y in train_loader_subset:\n",
    "    train_data.append(x.detach())\n",
    "    train_label.append(y.detach())\n",
    "synthetic_data = torch.vstack(train_data).to(device)\n",
    "synthetic_label = torch.hstack(train_label).to(device)\n",
    "\n",
    "for ipc in tqdm([0, 2, 10, 50, 250]):\n",
    "    if ipc != 0:\n",
    "        label_indices = [[] for _ in range(train_n_classes)]\n",
    "        for i, (x,y) in enumerate(dst_train):\n",
    "            label_indices[y].append(i)\n",
    "        seed(1)\n",
    "        for list in label_indices:\n",
    "            shuffle(list)\n",
    "        indices = []\n",
    "        for list in label_indices:\n",
    "            indices += list[:ipc]\n",
    "        dst_train_subset = torch.utils.data.Subset(dst_train, indices)\n",
    "        train_loader_subset = torch.utils.data.DataLoader(dst_train_subset, batch_size=256, shuffle=False, num_workers=8)\n",
    "        train_data = []\n",
    "        train_label = []\n",
    "        for x,y in train_loader_subset:\n",
    "            train_data.append(x.detach())\n",
    "            train_label.append(y.detach())\n",
    "        train_data = torch.vstack(train_data).to(device)\n",
    "        train_label = torch.hstack(train_label).to(device)\n",
    "        new_data = torch.vstack([synthetic_data, train_data]).to(device)\n",
    "        new_label = torch.hstack([synthetic_label, train_label]).to(device)\n",
    "    else:\n",
    "        new_data = synthetic_data.to(device)\n",
    "        new_label = synthetic_label.to(device)\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(1)\n",
    "    distilled_model = get_network(\"ConvNet\", channel, train_n_classes, im_size).to(device)\n",
    "    optim = torch.optim.SGD(distilled_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    distilled_model.train()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for e in range(300):\n",
    "        pred = distilled_model(new_data)\n",
    "        assert len(pred) == 1\n",
    "        loss = criterion(pred[-1], new_label)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    distilled_model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    test_predictions = []\n",
    "    correctness = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = distilled_model(x)\n",
    "            assert len(pred) == 1\n",
    "            pred = torch.argmax(pred[-1], dim=1)\n",
    "            test_predictions += pred.tolist()\n",
    "            correctness += (pred == y).tolist()\n",
    "            correct += torch.sum(pred == y).item()\n",
    "            total += x.shape[0]\n",
    "    test_accuracy = correct/total\n",
    "    rand_acc.append(test_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b748055b-bd07-4aaa-a29f-17cfa521e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "colours = [\"#000000\", \"#E69F00\", \"#0072B2\", \"#009E73\", \"#CC79A7\"]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "# visualize pixel intensity of distilled data\n",
    "inv_transform = T.Compose([  T.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                std = [ 1/0.2023, 1/0.1994, 1/0.2010 ]),\n",
    "                            T.Normalize(mean = [ -0.4914, -0.4822, -0.4465 ],\n",
    "                                std = [ 1., 1., 1. ]),\n",
    "                        ])\n",
    "data = torch.load(f\"../../DD_data/3.pt\")\n",
    "synthetic_data = data[\"data\"].detach().cpu()\n",
    "data = torch.load(f\"../../DD_data//1.pt\")\n",
    "synthetic_data2 = data[\"data\"].detach().cpu()\n",
    "sns.kdeplot(inv_transform(test_img[3,:,:,:]).cpu().flatten(), label='Real', fill=True, color=colours[0])\n",
    "sns.kdeplot(inv_transform(synthetic_data2[9,:,:,:]).flatten(), label='Dist Matching', fill=True, color=colours[2])\n",
    "sns.kdeplot(inv_transform(synthetic_data[8,:,:,:]).flatten(), label='Traj Matching', fill=True, color=colours[4])\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "labels = [\"BPTT\", \"Dist Matching\", \"Grad Matching\", \"Traj Matching\"]\n",
    "markers = [\"s\", \"o\", \"*\", \"^\"]\n",
    "plt.plot([0, 2, 10, 50, 250], rand_acc, marker='D', linestyle='dashed', label='Random Subset', markeredgecolor='black',c=colours[0])\n",
    "for i in range(4):\n",
    "    plt.plot([0, 2, 10, 50, 250], np.array(ipc_acc)[:,i], marker=markers[i], label=labels[i], markeredgecolor='black',c=colours[i+1])\n",
    "plt.xscale('symlog')\n",
    "ticks = [0, 2, 10, 50, 250]\n",
    "labels = ['10\\n+0', '10\\n+2', '10\\n+10', '10\\n+50', '10\\n+250']\n",
    "\n",
    "plt.xticks(ticks, labels)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.15, 0.62)\n",
    "plt.text(-0.3,0.1090,\"# Distilled\\n# Real\", horizontalalignment='right', fontstyle='italic', fontweight='bold')\n",
    "\n",
    "plt.subplots_adjust(left=0.02, right=0.99, wspace=0.175)\n",
    "plt.legend(ncol=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
